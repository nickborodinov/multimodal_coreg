{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated feature finding and co-registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy import ndimage as ndi\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['savefig.dpi']=600\n",
    "pgf_with_rc_fonts = {\n",
    "    \"font.family\": \"Arial\",\n",
    "    \"font.serif\": [], \n",
    "     \"font.size\"   : 20,\n",
    "    \"axes.titlesize\" : 20,\n",
    "    \"font.sans-serif\": [\"Times New Roman\"], # use a specific sans-serif font\n",
    "}\n",
    "mpl.rcParams.update(pgf_with_rc_fonts)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy import signal, stats\n",
    "from sklearn.decomposition import NMF\n",
    "from numpy import genfromtxt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_distance(a, b):\n",
    "    x1, y1 = a\n",
    "    x2, y2 = b\n",
    "    distance = np.sqrt((x2-x1)**2+(y2-y1)**2)\n",
    "    return distance\n",
    "\n",
    "def crawldir(topdir=[], ext='sxm'):\n",
    "    fn = dict()\n",
    "    for root, dirs, files in os.walk(topdir):\n",
    "              for name in files:\n",
    "              \n",
    "                if len(re.findall('\\.'+ext,name)):\n",
    "                    addname = os.path.join(root,name)\n",
    "\n",
    "                    if root in fn.keys():\n",
    "                        fn[root].append(addname)\n",
    "\n",
    "                    else:\n",
    "                        fn[root] = [addname]    \n",
    "    return fn\n",
    "        \n",
    "def gamma_correlation(array, feature, window_size):\n",
    "    \n",
    "    size = feature.size\n",
    "    \n",
    "    in_array=array-np.min(array)\n",
    "    in_array=in_array/np.max(in_array)\n",
    "    \n",
    "    arr = feature.arr\n",
    "    arr=cv2.resize(arr,(2*window_size,2*window_size))\n",
    "\n",
    "    try:\n",
    "        AA=np.array(stats.spearmanr(np.ndarray.flatten(arr),np.ndarray.flatten(in_array)))\n",
    "    except ValueError:\n",
    "\n",
    "        AA=0\n",
    "    return AA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function_ls class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class function_ls:\n",
    "    import numpy\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    def __init__(self,function,target,feature,epochs=500,alpha=0.1,decay=0.1,verbose=0):\n",
    "        ### function fitter that performs optimization for a multivariate function\n",
    "        self.target=target\n",
    "        self.function=function\n",
    "        self.parameters='None'\n",
    "        self.guesses='None'\n",
    "        self.epochs=epochs\n",
    "        self.alpha=alpha\n",
    "        self.decay=decay\n",
    "        self.verbose=verbose\n",
    "    def load_guesses(self,guesses):\n",
    "        self.guesses=guesses\n",
    "    def calc_rmse(self,parameters):\n",
    "        return np.sum((self.function(*parameters)-self.target)**2)**0.5\n",
    "    def gradient_descent_step(self):\n",
    "        if self.parameters=='None':\n",
    "            self.parameters=self.guesses\n",
    "        for i in range(len(self.parameters)):\n",
    "            altered_parameters_p=np.copy(self.parameters)\n",
    "            altered_parameters_p[i]=altered_parameters_p[i]*(1+self.alpha)\n",
    "            \n",
    "            altered_parameters_m=np.copy(self.parameters)\n",
    "            altered_parameters_m[i]=altered_parameters_m[i]*(1-self.alpha)\n",
    "            \n",
    "            altered_parameters=np.copy(self.parameters)\n",
    "            altered_parameters[i]=altered_parameters[i]*(1)\n",
    "            \n",
    "            min_idx=np.argmin(np.array([self.calc_rmse(altered_parameters_m),self.calc_rmse(altered_parameters),self.calc_rmse(altered_parameters_p)]))\n",
    "            self.parameters=np.array([altered_parameters_m,altered_parameters,altered_parameters_p])[min_idx]\n",
    "        self.alpha=self.alpha*(1-self.decay)\n",
    "        return self.parameters\n",
    "    def fit(self):\n",
    "        if self.parameters=='None':\n",
    "            self.parameters=self.guesses\n",
    "        for iteration in range(self.epochs):\n",
    "           \n",
    "            stage=np.copy(self.parameters)\n",
    "            history=self.gradient_descent_step()\n",
    "#             if all(history==stage)==True:\n",
    "#                 print(history)\n",
    "#                 break\n",
    "            if self.verbose==1:\n",
    "                print(iteration)\n",
    "#         print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature(object):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self,size,template=None,rotation=0,flip=False):\n",
    "        self.arr = None\n",
    "        self.size = size\n",
    "        self.target = None\n",
    "        self._corner_array_()\n",
    "        if template != None:\n",
    "            if template.upper() == 'CORNER':\n",
    "                self._corner_array_()\n",
    "            elif template.upper() == 'SQUARE':\n",
    "                self._square_array_()\n",
    "            elif template.upper() == 'GAMMA':\n",
    "                self._gamma_array_()\n",
    "            else:\n",
    "                print('Feature template not recognized, defaulting to corner.')\n",
    "                self._corner_array_()\n",
    "        self.rotate(rotation)\n",
    "        if flip:\n",
    "            self.flip()\n",
    "        return\n",
    "        \n",
    "    def _corner_array_(self):\n",
    "        size = self.size\n",
    "        arr_1=np.ones([size,size])\n",
    "        arr_0=np.zeros([size,size])\n",
    "        arr_00=np.hstack([arr_0,arr_0,arr_0])\n",
    "        arr_0_0=np.vstack([arr_0,arr_0,arr_0,arr_0,arr_0])\n",
    "        arrt=np.hstack([arr_0,arr_1,arr_1])\n",
    "        arrm=np.hstack([arr_0,arr_1,arr_0])\n",
    "        arrb=np.hstack([arr_0,arr_0,arr_0])\n",
    "        arr=np.vstack([arr_00,arrt,arrm,arrb,arr_00])\n",
    "        arr=np.hstack([arr_0_0,arr,arr_0_0])\n",
    "        self.arr = arr\n",
    "        height, length = arr.shape\n",
    "        self.center = (height/2, length/2)\n",
    "        self.target = (height*0.5996, length*0.3996)\n",
    "        correction = (self.target[0]-self.center[0], self.target[1] - self.center[1])\n",
    "        self.correction = (correction[0], correction[1])\n",
    "        return\n",
    "        \n",
    "    def _square_array_(self):\n",
    "        size = self.size\n",
    "        arr_1=np.ones([size,size])\n",
    "        arr_0=np.zeros([size,size])\n",
    "        arr_00=np.hstack([arr_0,arr_0,arr_0])\n",
    "        arr_0_0=np.vstack([arr_0,arr_0,arr_0,arr_0,arr_0])\n",
    "        arrt=np.hstack([arr_0,arr_0,arr_0])\n",
    "        arrm=np.hstack([arr_0,arr_1,arr_0])\n",
    "        arrb=np.hstack([arr_0,arr_0,arr_0])\n",
    "        arr=np.vstack([arr_00,arrt,arrm,arrb,arr_00])\n",
    "        arr=np.hstack([arr_0_0,arr,arr_0_0])\n",
    "        self.arr = arr\n",
    "        height, length = arr.shape\n",
    "        self.center = (height/2, length/2)\n",
    "        self.target = self.center\n",
    "        correction = (self.target[0]-self.center[0], self.target[1] - self.center[1])\n",
    "        self.correction = (correction[0], correction[1])\n",
    "        return\n",
    "    \n",
    "    def _gamma_array_(self):\n",
    "        size = self.size\n",
    "        arr_1=np.ones([size,size])\n",
    "        arr_0=np.zeros([size,size])\n",
    "        arr_00=np.hstack([arr_0,arr_0,arr_0])\n",
    "        arr_0_0=np.vstack([arr_0,arr_0,arr_0,arr_0,arr_0])\n",
    "        arrt=np.hstack([arr_0,arr_1,arr_1])\n",
    "        arrm=np.hstack([arr_0,arr_1,arr_0])\n",
    "        arrb=np.hstack([arr_0,arr_1,arr_0])\n",
    "        arr=np.vstack([arr_00,arrt,arrm,arrb,arr_00])\n",
    "        arr=np.hstack([arr_0_0,arr,arr_0_0])\n",
    "        self.arr = arr\n",
    "        height, length = arr.shape\n",
    "        self.center = (height/2, length/2)\n",
    "        self.target = (height*0.5996, length*0.3996)\n",
    "        correction = (self.target[0]-self.center[0], self.target[1] - self.center[1])\n",
    "        self.correction = (correction[0], correction[1])\n",
    "        return\n",
    "        \n",
    "    def _set_target_(self):\n",
    "        pass\n",
    "    \n",
    "    def import_array(self, array):\n",
    "        self.arr = array\n",
    "        height, length = self.arr.shape\n",
    "        self.center = (height/2, length/2)\n",
    "        self._set_target_()\n",
    "        \n",
    "    def _invert_(self):\n",
    "        arr_flat = self.arr.flatten()\n",
    "        og_shape = self.arr.shape\n",
    "        inverted_arr = np.empty_like(arr_flat)\n",
    "        for i, j in enumerate(arr_flat):\n",
    "            if j == 1:\n",
    "                inverted_arr[i] = 0\n",
    "            elif j == 0:\n",
    "                inverted_arr[i] = 1\n",
    "        inverted_arr = inverted_arr.reshape(og_shape)\n",
    "        self.arr = inverted_arr\n",
    "        \n",
    "    def rotate(self, degrees):\n",
    "        '''\n",
    "        Function to rotate feature array in integer multiples of 90 degrees counterclockwise.\n",
    "        \n",
    "        Input:\n",
    "        --------\n",
    "        degrees : int\n",
    "            desired rotation in degrees counterclockwise. Must be an integer multiple of 90 degrees!\n",
    "        '''\n",
    "        \n",
    "        #Rotate the feature array itsef\n",
    "        if degrees % 90 != 0:\n",
    "            raise ValueError('degrees must be an integer multiple of 90 degrees')\n",
    "        rotations = degrees/90\n",
    "        self.arr = np.rot90(self.arr, rotations)\n",
    "        \n",
    "        #Apply rotation to target point coordinates\n",
    "        degrees = 360-degrees\n",
    "        sin = np.sin(np.deg2rad(degrees))\n",
    "        cos = np.cos(np.deg2rad(degrees))\n",
    "        x_t, y_t = self.target\n",
    "        x_c, y_c = self.center\n",
    "        x_t -= x_c\n",
    "        y_t -= y_c\n",
    "        x_n = x_t * cos - y_t * sin\n",
    "        y_n = x_t * sin + y_t * cos\n",
    "        x_t = x_n + x_c\n",
    "        y_t = y_n + y_c\n",
    "        self.target = (x_t, y_t)\n",
    "        correction = (self.target[0]-self.center[0], self.target[1] - self.center[1])\n",
    "        self.correction = (correction[0], correction[1])\n",
    "        return\n",
    "    \n",
    "    def flip(self):\n",
    "        '''\n",
    "        Flips feature array along its vertical axis, essentially providing a\n",
    "        mirror image of the original feature\n",
    "        '''\n",
    "        #Flip the feature array itself\n",
    "        self.arr = np.flip(self.arr, 1)\n",
    "        #Flip coordinates of target point\n",
    "        x_t, y_t = self.target\n",
    "        x_c, y_c = self.center\n",
    "        diff_x = x_c - x_t\n",
    "        x_n = x_c + diff_x\n",
    "        self.target = (x_n, y_t)\n",
    "        correction = (self.target[0]-self.center[0], self.target[1] - self.center[1])\n",
    "        self.correction = (correction[0], correction[1])\n",
    "        return\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureFinder(object):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, function=None, feature=None):\n",
    "        self.function = function\n",
    "        self.feature = feature\n",
    "        \n",
    "    def wiggle(self, rotation, scaling, shift_x, shift_y):\n",
    "        arr = cv2.resize(self.feature.arr,(window_size*2, window_size*2),interpolation=cv2.INTER_CUBIC)\n",
    "        rotation=-30+rotation*60\n",
    "        scaling=0.7+scaling*0.6\n",
    "        shift_x=int(-5+shift_x*10)\n",
    "        shift_y=int(-5+shift_y*10)\n",
    "\n",
    "        rotation_matrix = cv2.getRotationMatrix2D((window_size, window_size), rotation, scaling)\n",
    "        altered_not_shifted = cv2.warpAffine(arr, rotation_matrix, (2*window_size, 2*window_size))\n",
    "        shifted = np.roll(np.roll(altered_not_shifted,shift_x,axis=1),shift_y,axis=0)\n",
    "\n",
    "        return shifted \n",
    "    \n",
    "    def sliding_function(self,array,function,feature,window_size=32,step=1):\n",
    "        a1=array\n",
    "        x_1=window_size\n",
    "        y_1=window_size\n",
    "        a2=a1[x_1-window_size:x_1+window_size,y_1-window_size:y_1+window_size]\n",
    "        output=np.ndarray.flatten(function(a2,feature,window_size))\n",
    "        x_dim=len(np.arange(window_size,a1.shape[0]-window_size,step))\n",
    "        y_dim=len(np.arange(window_size,a1.shape[1]-window_size,step))\n",
    "        transformed=np.zeros([x_dim,y_dim,len(output)],dtype='float64')\n",
    "        #print(x_dim,y_dim)\n",
    "        x_count=0\n",
    "        y_count=0\n",
    "        for i in range(window_size,a1.shape[0]-window_size,step):\n",
    "            for j in range(window_size,a1.shape[1]-window_size,step):\n",
    "\n",
    "                x_1=i\n",
    "                y_1=j\n",
    "                a2=a1[x_1-window_size:x_1+window_size,y_1-window_size:y_1+window_size]\n",
    "\n",
    "                a3=function(a2, feature, window_size)\n",
    "                try:\n",
    "                    transformed[y_count,x_count]=np.ndarray.flatten(a3)\n",
    "                except TypeError:\n",
    "                    transformed[y_count,x_count]=0\n",
    "                x_count=x_count+1\n",
    "            x_count=0\n",
    "            y_count=y_count+1\n",
    "        return transformed\n",
    "    \n",
    "    def search_image(self, image, f_count, feature=None):\n",
    "        if feature == None:\n",
    "            feature = self.feature\n",
    "            \n",
    "        return fit_parameters\n",
    "    \n",
    "    def generate_heatmap(self, image, step, window_size):\n",
    "        DD = self.sliding_function(image,self.function,self.feature,window_size,step)\n",
    "        heatmap = np.real(DD[:,:,0])\n",
    "        return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Settings and Image Read-in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MALDI training images from binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'/home/tyler/Documents/Work/Ovchinnikova/ionmaps/'\n",
    "images_f_name = 'slide2_experimental_positive_ionMaps.pik'\n",
    "images_f_name = os.path.join(data_dir, images_f_name)\n",
    "images_file = open(images_f_name, 'rb')\n",
    "maldi_image_list = list(pickle.load(images_file))\n",
    "images_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(maldi_image_list)\n",
    "i_x, i_y = maldi_image_list[0].shape\n",
    "a_factor = 1/image_count\n",
    "if a_factor < 0.05:\n",
    "    a_factor = 0.05\n",
    "fig, ax = plt.subplots(1)\n",
    "plt.title('Sum image')\n",
    "for image in maldi_image_list:\n",
    "    ax.imshow(image, cmap='Greys_r', alpha=a_factor)\n",
    "print('Imported %i images'%(len(maldi_image_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature template generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 50 # Pixel-to-pixel distance, in micrometers\n",
    "monomer_size = 250    # Length of feature monomers, in micrometers\n",
    "length = monomer_size*2\n",
    "inversion_mode = False   #Set to True when fiduciary markers appear as dark features instead of as bright features in ion images\n",
    "template = 'corner'\n",
    "buffer = 0\n",
    "buffered_length = length + length * buffer\n",
    "length_px=buffered_length*(1/resolution)\n",
    "window_size=int(length_px/2*5/2)\n",
    "feat = feature(monomer_size, template=template, rotation=180, flip=False)\n",
    "if inversion_mode:\n",
    "    feat._invert_()\n",
    "arr = feat.arr\n",
    "f_size = feat.arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(arr)\n",
    "plt.title('Scaled Feature Template')\n",
    "ax.scatter(feat.center[0], feat.center[1], color='red')\n",
    "ax.scatter(feat.target[0], feat.target[1], color='green')\n",
    "print('Feature center = %f,%f'%(feat.center[0], feat.center[1]))\n",
    "print('Feature target = %f,%f'%(feat.target[0], feat.target[1]))\n",
    "print('Correction vector = %f,%f'%(feat.correction[0], feat.correction[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________\n",
    "Attempt to locate fiduciary markers in imported ion or PCA maps. Checks each map individually to build list of points identified in each image. Grabs two top most common values (mode) for x and y, infers list of identified rough anchor points from result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = FeatureFinder(gamma_correlation, feat)\n",
    "step = 3\n",
    "times = []\n",
    "print('Image :',' processing time :',' average time :',' total_time')\n",
    "heatmaps = []\n",
    "for idx, image in enumerate(maldi_image_list):\n",
    "    ti = time.time()\n",
    "    heatmap = ff.generate_heatmap(image, step, window_size)\n",
    "    dt = time.time()-ti\n",
    "    times.append(dt)\n",
    "    average_time = sum(times) / len(times)\n",
    "    heatmaps.append(heatmap)\n",
    "    print(idx+1,':', dt,':', average_time,':', sum(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import peak_local_max\n",
    "min_distance = int(1/(step/10)+1)\n",
    "rough_feature_top3 = []\n",
    "for heatmap in heatmaps:\n",
    "    local_maxima = peak_local_max(heatmap, min_distance=min_distance)\n",
    "    local_maxima = np.flip(local_maxima,1)\n",
    "    maxima_scores = []\n",
    "    for y,x in local_maxima:\n",
    "        heatmap_value = heatmap[x, y]\n",
    "        maxima_scores.append(heatmap_value)\n",
    "        sorted_maxima_scores = [score for score in maxima_scores]\n",
    "        sorted_maxima_scores.sort()\n",
    "        sorted_maxima_scores.reverse()\n",
    "        top_3_coords = np.empty((3,2), dtype=int)\n",
    "        n_top_3_coords = np.empty_like(top_3_coords, dtype=float)\n",
    "        max_y, max_x = heatmap.shape\n",
    "    for i in range(3):\n",
    "        score = sorted_maxima_scores[i]\n",
    "        index = maxima_scores.index(score)\n",
    "        x, y = local_maxima[index]\n",
    "        coordinate = (x, y)\n",
    "        n_coordinate = (x/max_x, y/max_y)\n",
    "        top_3_coords[i]=coordinate\n",
    "        n_top_3_coords[i] = n_coordinate\n",
    "    rough_feature_top3.append(top_3_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rough_feature_top3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-64ea70ada5c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrough_feature_top3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mfull_pointlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mfull_pointlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rough_feature_top3' is not defined"
     ]
    }
   ],
   "source": [
    "full_pointlist = []\n",
    "xs = []\n",
    "ys = []\n",
    "for a,b,c in rough_feature_top3:\n",
    "    full_pointlist.append(tuple(a))\n",
    "    full_pointlist.append(tuple(b))\n",
    "    full_pointlist.append(tuple(c))\n",
    "for x, y in full_pointlist:\n",
    "    xs.append(x)\n",
    "    ys.append(y)\n",
    "mode_x1 = stats.mode(xs)[0]\n",
    "mode_y1 = stats.mode(ys)[0]\n",
    "while True:\n",
    "    try:\n",
    "        xs.remove(mode_x1)\n",
    "    except ValueError:\n",
    "        break\n",
    "while True:\n",
    "    try:\n",
    "        ys.remove(mode_y1)\n",
    "    except ValueError:\n",
    "        break\n",
    "mode_x2 = stats.mode(xs)[0]\n",
    "mode_y2 = stats.mode(ys)[0]\n",
    "if abs(mode_x1 - mode_x2) < 3:\n",
    "    while True:\n",
    "        try:\n",
    "            xs.remove(mode_x2)\n",
    "        except ValueError:\n",
    "            break\n",
    "    mode_x2 = stats.mode(xs)[0]\n",
    "if abs(mode_y1 - mode_y2) < 3:\n",
    "    while True:\n",
    "        try:\n",
    "            ys.remove(mode_y2)\n",
    "        except ValueError:\n",
    "            break\n",
    "    mode_y2 = stats.mode(ys)[0]\n",
    "rough_anchors = [(mode_x1[0], mode_y1[0]),(mode_x1[0], mode_y2[0]),(mode_x2[0], mode_y1[0])]\n",
    "scaled_rough_anchors = [(x*step+window_size,y*step+window_size) for (x,y) in rough_anchors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "plt.title('Rough Anchor Point Guesses')\n",
    "for heatmap in heatmaps:\n",
    "    ax.imshow(heatmap, alpha = 0.1, cmap = 'Greys_r')\n",
    "for x, y in full_pointlist:\n",
    "    ax.scatter(x,y,color='blue')\n",
    "for x, y in rough_anchors:\n",
    "    ax.scatter(x,y,color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(maldi_image_list[3], cmap = 'hot')\n",
    "for (x,y) in scaled_rough_anchors:\n",
    "    plt.scatter(x,y,color='blue')\n",
    "print(scaled_rough_anchors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors_list = []\n",
    "kernel = np.ones((3,3),np.float32)/3\n",
    "arr_n = cv2.resize(feat.arr, (2*window_size, 2*window_size))\n",
    "rescale_factor = arr_n.shape[0]/feat.arr.shape[0]\n",
    "feature_correction = [coord*rescale_factor for coord in feat.correction]\n",
    "    \n",
    "for image in maldi_image_list:\n",
    "    top_3_fitted_parameters = np.empty((3,4,2))\n",
    "    windows = []\n",
    "    window_coords = []\n",
    "    for idx, (x,y) in enumerate(scaled_rough_anchors):\n",
    "        x_1 = x\n",
    "        y_1 = y\n",
    "        window_coords.append([x_1, y_1])\n",
    "        check = image[y_1-window_size:y_1+window_size, x_1-window_size:x_1+window_size]\n",
    "        check = cv2.filter2D(check, -1, kernel)\n",
    "        check = check - np.min(check)\n",
    "        check = check / np.max(check)\n",
    "        find_marker = function_ls(function=ff.wiggle, target=check, feature=feat, epochs=200, alpha=0.5, decay=0.05, verbose=1)\n",
    "        find_marker.load_guesses(np.array([0.5,0.5,0.5,0.5]))\n",
    "        find_marker.verbose = False\n",
    "        find_marker.fit()\n",
    "        rotation, scaling, shift_x, shift_y = find_marker.parameters\n",
    "        recalc_parameters = np.array([rotation*60-30, \n",
    "                                      scaling*0.6+0.7,\n",
    "                                      shift_x*10-5,\n",
    "                                      shift_y*10-5])\n",
    "        fitted_parameters = np.empty((4,2))\n",
    "        fitted_parameters[:,0] = find_marker.parameters\n",
    "        fitted_parameters[:,1] = recalc_parameters\n",
    "        top_3_fitted_parameters[idx] = fitted_parameters\n",
    "    operators = []\n",
    "    for i in range(3):\n",
    "        rotation_degrees = top_3_fitted_parameters[i,0,1]\n",
    "        #rotation_radians = np.deg2rad(rotation_degrees)\n",
    "        S = top_3_fitted_parameters[i,1,1]\n",
    "        R = cv2.getRotationMatrix2D((window_size, window_size), rotation_degrees, S)\n",
    "        T = np.array([top_3_fitted_parameters[i,2,1], top_3_fitted_parameters[i,3,1]])\n",
    "        op_set = [R,S,T]\n",
    "        operators.append(op_set)\n",
    "    anchors = []\n",
    "    for i, op_set in enumerate(operators):\n",
    "        R = op_set[0][:,:2]\n",
    "        S = op_set[1]\n",
    "        T = op_set[2]\n",
    "        start_center = list(window_coords[i])\n",
    "        fit_center = [start_center[j] + T[j] for j in range(2)]\n",
    "        correction_vector = np.matrix(feature_correction)*R*S\n",
    "        correction_vector[0,1] = correction_vector[0,1]\n",
    "        anchor = [fit_center[j] + correction_vector[0,j] for j in range(2)]\n",
    "        anchors.append(anchor)\n",
    "    anchors=np.array(anchors)\n",
    "    anchors_list.append(anchors)\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    #for (x,y) in anchors:\n",
    "    #    plt.scatter(x,y,color='red')\n",
    "    #    s = '(%f,% f)'%(x, y)\n",
    "    #    plt.text(x+5, y+5, s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_anchors = []\n",
    "for i in range(3):\n",
    "    xs = [anchor_set[i][0] for anchor_set in anchors_list]\n",
    "    ys = [anchor_set[i][1] for anchor_set in anchors_list]\n",
    "    unique, counts = np.unique(xs, return_counts=True)\n",
    "    max_count = np.max(counts)\n",
    "    max_x = unique[np.where(counts==max_count)]\n",
    "    unique, counts = np.unique(ys, return_counts=True)\n",
    "    max_count = np.max(counts)\n",
    "    max_y = unique[np.where(counts==max_count)]\n",
    "    fitted_anchor = (max_x[0], max_y[0])\n",
    "    fitted_anchors.append(fitted_anchor)\n",
    "    print(fitted_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_anchors = []\n",
    "for i in range(3):\n",
    "    xs = np.array([anchor_set[i][0] for anchor_set in anchors_list])\n",
    "    ys = np.array([anchor_set[i][1] for anchor_set in anchors_list])\n",
    "    mean_x = np.mean(xs)\n",
    "    mean_y = np.mean(ys)\n",
    "    std_x = np.std(xs)\n",
    "    std_y = np.std(ys)\n",
    "    diffs_x = xs - mean_x\n",
    "    diffs_y = ys - mean_y\n",
    "    keep_x = np.where(np.abs(diffs_x) < std_x)[0]\n",
    "    keep_y = np.where(np.abs(diffs_y) < std_y)[0]\n",
    "    valid_points = []\n",
    "    for idx in keep_x:\n",
    "        if idx in keep_y:\n",
    "            valid_points.append(idx)\n",
    "    xs = [xs[i] for i in valid_points]\n",
    "    ys = [ys[i] for i in valid_points]\n",
    "    refined_mean_x = np.mean(xs)\n",
    "    refined_mean_y = np.mean(ys)\n",
    "    fitted_anchor = (refined_mean_x, refined_mean_y)\n",
    "    fitted_anchors.append(fitted_anchor)\n",
    "    print(fitted_anchor)\n",
    "fitted_anchors = np.array(fitted_anchors, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_factor = 1/image_count\n",
    "if a_factor < 0.05:\n",
    "    a_factor = 0.05\n",
    "fig, ax = plt.subplots(1)\n",
    "plt.title('Sum image')\n",
    "for image in maldi_image_list:\n",
    "    ax.imshow(image, cmap='Greys_r', alpha=a_factor)\n",
    "for (x,y) in fitted_anchors:\n",
    "    plt.scatter(x,y,color='red')\n",
    "plt.title('Fine fitting results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_sims_image_dir = r'/home/tyler/Documents/Work/Ovchinnikova/maldi-sims ion maps/sims/'\n",
    "sims_pickled_fname = r'sims_nmf_maps.pik'\n",
    "sims_pickled_fname = os.path.join(pickled_sims_image_dir, sims_pickled_fname)\n",
    "maldi_ion_image_dir = r'/home/tyler/Documents/Work/Ovchinnikova/maldi-sims ion maps/maldi/'\n",
    "maldi_pickled_fname = r'maldi_pca_map_dump.pik'\n",
    "maldi_pickled_fname = os.path.join(maldi_ion_image_dir, maldi_pickled_fname)\n",
    "output_dir = r'/home/tyler/Documents/Work/Ovchinnikova/maldi-sims ion maps/coregistered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_anchors = np.array([[212,325],\n",
    "                         [212,887],\n",
    "                         [1425,325]], dtype=np.float32)\n",
    "with open(sims_pickled_fname,'rb') as f:\n",
    "    pickled_maps = pickle.load(f)\n",
    "pickled_shape = pickled_maps[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cv2.getAffineTransform(fitted_anchors, sims_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(maldi_pickled_fname, 'rb') as f:\n",
    "    maldi_ion_maps = pickle.load(f)\n",
    "#registered_ion_maps = {}\n",
    "registered_ion_maps = [cv2.warpAffine(np.flip(np.rot90(maldi_ion_maps[:,:,i],3),1), m, (pickled_shape[1], pickled_shape[0])) for i in range(20)]\n",
    "#ion_map_masses = [key for key in maldi_ion_maps['mean'].keys()]\n",
    "#for key, ion_map in maldi_ion_maps['mean'].items():\n",
    "#    registered_ion_maps[key] = (cv2.warpAffine(ion_map, m, (pickled_shape[1], pickled_shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(registered_ion_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maldi_pullmap = registered_ion_maps[1]\n",
    "plt.figure()\n",
    "plt.imshow(maldi_pullmap)\n",
    "plt.figure()\n",
    "plt.imshow(np.flip(np.rot90(maldi_ion_maps[:,:,1],3),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_pullmap = pickled_maps[4]\n",
    "plt.imshow(sims_pullmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.imshow(maldi_pullmap, cmap='Reds', alpha=0.8)\n",
    "plt.imshow(sims_pullmap, cmap='Greens', alpha=0.4)\n",
    "figname = 'ion_map_%s.png'%('maldi pca 3, sims nmf 5')\n",
    "figname = os.path.join(output_dir, figname)\n",
    "plt.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for image in mapped_maldi_images[:1]:\n",
    "    plt.imshow(image, alpha=0.9, cmap='Reds')\n",
    "for image in pickled_maps[:1]:\n",
    "    plt.imshow(image, alpha=0.7, cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(maldi_ion_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(maldi_ion_maps['mean'].keys())[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
